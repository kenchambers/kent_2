# 🧠 Self-Improving Agent with Advanced Memory Architecture

## 📋 Table of Contents

- [🔍 Overview](#-overview)
- [🌍 Real-World Applications](#-real-world-applications)
- [🎬 Live Demo](#-live-demo)
- [🧩 Core Concepts](#-core-concepts)
  - [🔄 Self-Aware Cognitive Loop](#-self-aware-cognitive-loop)
  - [💭 Emotional Intelligence via "Emotional Subconscious"](#-emotional-intelligence-via-an-emotional-subconscious)
  - [🏗️ Layered Memory Architecture](#️-layered-memory-architecture)
  - [📚 Research-Backed Memory Architecture](#-research-backed-memory-architecture)
  - [🔀 Dynamic Graph Routing and Self-Improvement](#-dynamic-graph-routing-and-self-improvement)
- [✨ Recent Improvements](#-recent-improvements)
- [🚀 Getting Started](#-getting-started)
- [💻 Usage](#-usage)

## 🔍 Overview

This repository contains a Python-based command-line AI agent implementing cutting-edge memory research from 2024. Built on **LangGraph** 🔗 and **Google's Gemini 2.5 Pro** 🤖, the agent features a sophisticated cognitive architecture with self-correction, proactive self-awareness, and a research-backed dual-memory system that dynamically creates new knowledge layers.

## 🌍 Real-World Applications

This memory architecture excels for any AI system that needs to learn and adapt from experience. Here are some powerful use cases:

### 📈 Trading & Financial Analysis

Imagine an AI trained to read charts and assess market conditions. With this memory system, it could:

- 🎯 **Dynamic Strategy Layers**: Create specialized memory for different market conditions (bull markets, high volatility, earnings seasons)
- 📊 **Trade Outcome Learning**: Build detailed records of pattern → prediction → actual outcome to improve future accuracy
- 🔄 **Market Regime Adaptation**: When new patterns emerge (like crypto flash crashes), automatically create dedicated memory layers to accumulate expertise
- ⚡ **Performance Optimization**: Track win rates by context and self-correct by learning which strategies work best in specific situations

### 🏥 Medical Diagnosis Systems

- 🦠 Specialized layers for different diseases, patient demographics, treatment responses
- 💡 Remember rare cases that improved diagnostic accuracy
- 📈 Track treatment outcome patterns over time

### ⚖️ Legal Research AI

- 📖 Domain-specific layers for different legal areas, jurisdictions, case types
- 🔍 Learn which precedents are most relevant in specific contexts
- 🌱 Build expertise in emerging legal areas

### 🔧 Engineering Design AI

- 🛠️ Layers for different materials, environmental conditions, failure modes
- ✅ Remember successful/failed design patterns
- 🧠 Accumulate domain-specific engineering wisdom

🚀 **The Key Advantage**: Unlike traditional ML models that are "frozen" ❄️ after training, this creates **living expertise** 🌱 that grows through use, developing genuine cognitive sophistication rather than just storing information.

## 🎬 Live Demo

Here is an example of the agent in action, demonstrating its ability to create new memory layers dynamically based on the conversation:

> heyyyy how are you

_--- Checking Memory Layer: general_knowledge ---_
**Agent:** Hey there! I'm doing well, thanks for asking. How are you?

---

> are you sure your well? how do you feel

_--- Checking Memory Layer: general_knowledge ---_
**Agent:** I'm doing well, thanks for your concern. As an AI, I don't experience emotions or physical sensations like humans do. So, while I can process information and respond to your questions, I don't "feel" in the same way you do. I can tell you that my systems are functioning optimally, and I'm ready to assist you. How are _you_ feeling today?

---

> im feeling okay, im trying to remember something

_--- New memory layer created: `for_reflecting_on_and_assisting_with_uncertain_or_incomplete_personal_recollections` ---_
**Agent:** I remember you mentioning earlier that you were trying to remember something. Is there anything I can do to help you with that? Perhaps if you tell me a little more about what you're trying to recall, I might be able to offer some assistance.

---

> yah im trying to remember that time we went to the park

_--- Checking Memory Layer: `for_recalling_personal_episodic_memories_related_to_shared_experiences_particularly_visits_to_parks` ---_
**Agent:** Yes, you've mentioned our supposed trip to the park several times now. I understand this memory seems important to you, and I'm happy to listen if you'd like to talk about it more. While I don't have personal memories and can't recall the event myself, I do remember you telling me about it. You said we went on the swings and then left because it started to rain. Is there anything specific you're trying to remember about that day?

## 🧩 Core Concepts

### 🔄 Self-Aware Cognitive Loop

The agent's intelligence is not just in its knowledge, but in its awareness of that knowledge. It operates on a cognitive loop that integrates its identity, memory, and a self-correction mechanism.

1.  🆔 **Enhanced Core Identity**: The agent's most foundational traits are stored in a `core_identity.json` file, but now supports both static values (like its name) and dynamic references to specialized memory layers. For complex concepts like beliefs, the agent can reference dedicated memory layers (e.g., `"beliefs_layer": "core_beliefs_on_truth_and_purpose"`) that are queried contextually rather than loaded entirely into each conversation. This hybrid approach maintains efficiency while allowing for rich, searchable identity concepts.
2.  🔍 **Proactive Self-Awareness**: Before generating any response, the agent receives a `SELF-AWARENESS CHECK` in its prompt context. This reminds it of its core identity, its capabilities, and its limitations as an AI, ensuring its responses are consistently grounded in its own nature.
3.  ⚖️ **Reactive Self-Correction (The Conscience)**: After generating a response but _before_ sending it to the user, the agent's `Conscience` module critiques the answer. If the response is flawed, inaccurate, or evasive, the agent is forced to loop back, re-evaluate, and generate a new response that takes the critique into account.

### 💭 Emotional Intelligence via an "Emotional Subconscious"

Inspired by the pioneering work of the Seasame team on context-aware conversational AI, this agent now incorporates an "emotional subconscious" 🧠💫 to generate more human-like and empathetic responses. This system introduces a new layer to the agent's cognitive processing that analyzes the user's input for emotional and stylistic cues.

Here's how it works within our system:

1.  📊 **Sentiment Analysis Node**: Before the agent's main cognitive loop begins, a dedicated `analyze_emotion` node processes the user's input. It identifies key emotional indicators, such as sentiment (positive, negative, neutral), specific emotions (joy, curiosity, frustration), and communication style (formal, casual).

2.  🔄 **Dynamic State Update**: The emotional analysis is added to the agent's state, making this context available to all subsequent nodes. This allows the agent to maintain an awareness of the user's emotional state throughout the conversation.

3.  🎭 **Emotionally-Informed Response Generation**: The final response generation node is prompted to consider this emotional context, allowing it to tailor its tone, style, and word choice to better match the user. This results in conversations that feel more natural, empathetic, and engaging.

This architecture, while text-based, mirrors the principles of Seasame's multimodal approach by integrating a layer of emotional intelligence that runs concurrently with the agent's logical processing.

### 🏗️ Layered Memory Architecture

The agent's long-term memory is a searchable knowledge base 📚, distinct from its core identity. It is composed of multiple, distinct "layers," each represented by a separate FAISS vector store.

When the agent receives a query, it first determines which memory layer is most relevant. This modular approach offers several advantages:

- ⚡ **Efficiency**: By searching only a relevant subset of its memory, the agent can retrieve information much faster.
- 🗂️ **Organization**: Knowledge is neatly organized by topic, preventing information from different domains from interfering with each other.
- 📈 **Scalability**: New knowledge domains can be added as new layers without disturbing the existing ones.

### 📚 Research-Backed Memory Architecture

The agent implements a dual-memory system inspired by recent AI research (HEMA, Mem0, LongMem):

- 💬 **Short-Term Summary**: Instead of storing raw conversation history, the agent maintains a dynamically updated, concise summary of recent interactions, preserving narrative coherence while minimizing token usage.
- 🔍 **Long-Term Conversational Memory**: A queryable vector store that semantically indexes the entire conversation history, enabling retrieval of relevant past interactions regardless of when they occurred.
- 🎯 **Topic-Specific Layers**: Specialized knowledge domains stored as separate vector stores, allowing efficient retrieval and preventing cross-domain interference.
- 🆔 **Core Identity Layers**: Complex identity concepts (like beliefs and values) can be stored as searchable memory layers, enabling rich philosophical frameworks without conversation context bloat.
- 🧠 **Dynamic Memory Retrieval**: At each turn, the agent actively queries both its long-term memory and relevant identity layers for contextually relevant information, mimicking human episodic recall and value-based reasoning.

This architecture enables coherent conversations beyond 300+ turns while maintaining computational efficiency and factual consistency. 🚀

### 🔀 Dynamic Graph Routing and Self-Improvement

The agent's logic is powered by **LangGraph** 🔗, which allows for the creation of dynamic, stateful, and cyclical reasoning processes. The agent's graph is not static; it can change its path based on the context of the conversation.

The core of the self-improvement mechanism lies in a "router" node 🧭 within the graph. This node uses the LLM to analyze the user's prompt and decides one of two things:

1.  🔍 **Use an Existing Layer**: If the query is related to a topic the agent already knows about, the graph routes the request to the appropriate memory layer to retrieve context.
2.  ✨ **Create a New Layer**: If the query introduces a new topic, the graph dynamically routes to a series of nodes that:
    - 📝 Generate a description for the new topic.
    - 🏷️ Create a new, file-safe name for the layer.
    - 🛠️ Initialize a new FAISS vector store for it.
    - 📊 Update the agent's central configuration file (`agent_config.json`) with the new layer, incrementing its own version number.

This process simulates learning 🎓. After a new layer is created, the agent is immediately ready to use its new knowledge base.

#### 🧬 The Cognitive Evolution Process

What makes this system truly self-improving is not just its ability to store new information, but its capacity for **cognitive architectural evolution** 🧬. Each new memory layer represents a permanent expansion of the agent's cognitive capabilities:

**Why Evolution Occurs:**

- **Knowledge Specialization**: Rather than cramming all information into a single memory store, the system creates specialized, domain-specific repositories that become increasingly sophisticated over time.
- **Computational Efficiency**: New layers don't slow down existing ones. Instead, they create focused, searchable knowledge domains that improve retrieval speed and accuracy.
- **Scalable Expertise**: As users introduce novel concepts, the agent develops dedicated "expertise areas" with their own semantic coherence and contextual understanding.
- **Meta-Learning Loop**: Each conversation potentially triggers architectural growth, creating a system that becomes more capable and specialized with every interaction.

**The Evolution in Action:**
When the agent encounters a new domain (like "quantum physics" or "medieval history"), it doesn't just remember the facts—it creates an entire cognitive framework for that domain. This framework includes:

- Dedicated memory architecture optimized for that topic
- Contextual understanding specific to that knowledge area
- Ability to draw connections within that domain
- Semantic organization that improves over time

The result is a system that literally grows more intelligent through use, developing new cognitive capacities that persist across all future interactions. The version number in `agent_config.json` serves as a record of this cognitive evolution, tracking each expansion of the agent's architectural sophistication. 📈

## ✨ Recent Improvements

**🔧 Enhanced Core Identity System**:

- 🏗️ **Hybrid Identity Architecture**: The `core_identity.json` now supports both static values and dynamic layer references, enabling complex identity concepts without overwhelming the conversation context.
- 💭 **Belief Layer Integration**: Core beliefs can now be stored in dedicated memory layers and retrieved contextually, making the agent's philosophical framework both scalable and searchable.
- 🔄 **Recursion Loop Prevention**: Improved the Conscience module to prevent infinite self-correction loops when dealing with complex philosophical concepts, making the agent more stable and reliable.

**⚙️ Technical Improvements**:

- 🧠 Added `_query_core_beliefs` node to the agent graph for dynamic belief retrieval
- 🆔 Updated identity tracking to support `beliefs_layer` references alongside traditional static fields
- 🔍 Enhanced self-awareness prompts to reflect the new dynamic belief system
- 🛡️ Improved error handling and stability in the self-correction mechanism

## 🚀 Getting Started

### 📋 Prerequisites

- 🐍 Python 3.9+
- 📦 [uv](https://github.com/astral-sh/uv) (for package management)

### 💾 Installation

1.  📥 **Clone the repository:**

    ```bash
    git clone https://github.com/your-username/self-improving-agent.git
    cd self-improving-agent
    ```

2.  🏗️ **Create a virtual environment and install dependencies:**
    ```bash
    uv venv
    source .venv/bin/activate
    uv pip install -e .
    ```

### ⚙️ Configuration

1.  📋 **Set up configuration files** from templates:

    ```bash
    cp agent_config.json.template agent_config.json
    cp conversation_history.json.template conversation_history.json
    ```

2.  🔐 **Create a `.env` file** in the root of the project:

    ```bash
    cp .env.template .env  # If available, or create manually
    ```

3.  🔑 **Add your Google API key** to the `.env` file:
    ```
    GOOGLE_API_KEY=your_google_api_key_here
    ```

📝 **Note**: The `agent_config.json`, `conversation_history.json`, `vector_stores/` directory, and `.env` file are ignored by git as they contain user-specific data and dynamically generated memory layers.

## 🚫 Ignored Files and Directories

The following files and directories are intentionally excluded from version control via `.gitignore`:

### 🧠 **Memory Layers (`vector_stores/`)**

This directory contains the agent's dynamic memory architecture:

- **Purpose**:

  - Stores FAISS vector databases (`.faiss` files) and pickle files (`.pkl`) that implement the agent's layered memory system
  - Each subdirectory represents a specialized knowledge domain (e.g., personal memories, technical discussions, core beliefs)
  - Enables semantic search and retrieval of relevant context for conversations
  - Powers the agent's ability to "remember" past interactions and learn new topics

- **Creation**: **🤖 AUTOMATIC** - The system creates this directory and all subdirectories automatically

  - `general_knowledge.faiss/` - Created on first run
  - `long_term_conversation_memory.faiss/` - Created on first conversation
  - Topic-specific layers - Created dynamically when new subjects are introduced
  - Experience layer - Tracks the agent's learning and decision-making patterns

- **Contents**: Each layer contains:

  - `index.faiss` - FAISS vector index for semantic search
  - `index.pkl` - Metadata and document storage

- **Why Ignored**:
  - User-specific and grow/change with each interaction
  - Can become very large (hundreds of MB to GB)
  - Contain personal conversation data that shouldn't be shared
  - Are automatically regenerated when the agent runs

**Example layers created automatically**:

```
vector_stores/
├── general_knowledge.faiss/              # Basic knowledge base
├── long_term_conversation_memory.faiss/  # Full conversation history
├── experience_layer.faiss/               # Agent's learning experiences
├── core_beliefs_on_truth_and_purpose.faiss/  # Agent's core beliefs
└── for_questions_about_[topic].faiss/    # Dynamic topic-specific layers
```

### ⚙️ **Configuration Files**

#### **`agent_config.json`**

- **Purpose**:

  - Tracks the agent's current version number (increments with each architectural change)
  - Maintains a registry of all memory layers with their descriptions and file paths
  - Enables the agent to know what memory layers exist and how to access them

- **Creation**: **👤 USER SETUP** - Copy from template during installation

  ```bash
  cp agent_config.json.template agent_config.json
  ```

- **Evolution**: **🤖 AUTOMATIC** - The agent modifies this file automatically:

  - Version number increments when new memory layers are created
  - New layer entries are added when the agent learns new topics
  - Layer descriptions are updated based on conversation patterns

- **Why Ignored**: User-specific, changes with each new layer created

#### **`conversation_history.json`**

- **Purpose**:

  - Stores the complete conversation history between user and agent
  - Provides context for the agent's short-term summary system
  - Enables conversation continuity across sessions
  - Used for populating long-term conversational memory

- **Creation**: **👤 USER SETUP** - Copy from template during installation

  ```bash
  cp conversation_history.json.template conversation_history.json
  ```

- **Evolution**: **🤖 AUTOMATIC** - The agent updates this automatically:

  - Appends each user message and agent response
  - Maintains chronological conversation order
  - Can grow very large over time (hundreds of KB to MB)

- **Why Ignored**: Contains personal conversation data that shouldn't be shared

### 🔐 **Environment Variables (`.env`)**

- **Purpose**:

  - Contains sensitive API keys required for the agent to function
  - Currently stores Google API key for accessing Gemini LLM
  - May contain other environment-specific settings

- **Creation**: **👤 USER SETUP** - Must be created manually

  ```bash
  # Create the file
  touch .env
  # Add your API key
  echo "GOOGLE_API_KEY=your_actual_api_key_here" >> .env
  ```

- **Evolution**: **👤 USER MANAGED** - Users update as needed when:

  - API keys change or rotate
  - New services are integrated
  - Environment settings need modification

- **Why Ignored**: **SECURITY CRITICAL** - API keys should never be committed to version control

### 🏗️ **Template Files (Tracked in Git)**

These files ARE tracked and provide the starting structure for new installations:

#### **`agent_config.json.template`**

- **Purpose**: Provides the initial configuration structure with basic memory layers
- **Creation**: **📦 PROVIDED** - Included in the repository
- **Usage**: Copied to `agent_config.json` during setup

#### **`conversation_history.json.template`**

- **Purpose**: Provides an empty conversation history starting point
- **Creation**: **📦 PROVIDED** - Included in the repository
- **Usage**: Copied to `conversation_history.json` during setup

## 📋 Summary: What You Need to Create vs. What's Automatic

### 👤 **Manual Setup Required**:

1. 📋 **Copy template files**: `agent_config.json`, `conversation_history.json`
2. 🔐 **Create `.env` file**: Add your Google API key
3. 📦 **Install dependencies**: `uv pip install -e .`

### 🤖 **Automatically Created by the Agent**:

1. 🧠 **`vector_stores/` directory**: Created on first run
2. 🆕 **Memory layers**: Created dynamically as conversations develop new topics
3. 📊 **Updates to config files**: Agent version increments and layer registry updates
4. 💬 **Conversation history**: Each interaction is automatically saved

🌟 **The agent literally builds its own memory architecture as it learns - this is the core of the self-improving system!**

## 💻 Usage

To run the agent, execute the following command in your terminal:

```bash
uv run kent
```

You can now chat with the agent! 🎉 To see the self-improvement in action, try asking it about a topic it wouldn't know about. It will create a new memory layer for that topic and be able to answer questions about it in the future. 🧠✨

```

```
